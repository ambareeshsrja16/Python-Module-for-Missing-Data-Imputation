{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIDA Gondara and Wang(2018) in Python (using PyTorch)\n",
    "https://arxiv.org/abs/1705.02737\n",
    "https://gist.github.com/lgondara/18387c5f4d745673e9ca8e23f3d7ebd3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Dataset\n",
    "\n",
    "## 1.1. Load a dataset and introduce missingness\n",
    "\n",
    "Dataset used: Shuttle Dataset (https://archive.ics.uci.edu/ml/datasets/Statlog+(Shuttle)\n",
    "\n",
    "### 1.1.1. Load the dataset and store it as dataframe(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "filename = \"data/shuttle/shuttle_trn\"\n",
    "df = utils.get_dataframe_from_csv(filename).iloc[:,:-1]  #remove label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test\n",
    "# filename = \"data/shuttle/shuttle_trn_debug\"\n",
    "# train_df = utils.get_dataframe_from_csv(filename).iloc[:,:-1]  #remove label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Inducing missingness\n",
    "\n",
    "After dataset loading, start with inducing missingness. \n",
    "\n",
    "To start off, introduce simple random missing patterns (Missing Completely At Random), i.e. sample half of the variables and set observations in those variables to missing if an appended random uniform vector has value less than a certain threshhold. WIth threshold of 0.2, the procedure should introduce about 20% missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df1 = df[:]\n",
    "df2 = utils.induce_missingness(df1,logger_level=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Create Train-Test split\n",
    "\n",
    "Create 70% training data and 30%  test data which includes missingness and a test data without missingness so we can calculate performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "train_df, test_df, full_test_df = utils.create_train_test_split(dataframe=df1, test_perc=0.3, logger_level=20)\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(full_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling\n",
    "\n",
    "Proceed to modelling.\n",
    "\n",
    "In R:\n",
    "Start with initializing 'h2o' package and then reading the training and test datasets as the 'h2o's supported format.\n",
    "Then run imputation model multiple times as each new start would initialize the weights with different values.<br>\n",
    "Info at: <br>\n",
    "[h2o](https://cran.r-project.org/web/packages/h2o/h2o.pdf) package offers an easy to use function for implementing autoencoders. \n",
    "More information is available at this [link](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/DeepLearningBooklet.pdf).\n",
    "\n",
    "In Python: Using PyTorch to create the DAE, and train using the Adam optimizer from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for device, randomization seed, default tensor type, kwargs for memory #DevSeedTensKwargs\n",
    "RANDOM_SEED = 18\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    kwargs = {'num_workers':4, 'pin_memory' :True}\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    kwards = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset_module.DataSetForImputation(train_df, normalize=True)  #normalize True for [0,1] normalization for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Modelling\n",
    "net = Modelling.DenoisingAutoEncoder(len(trainset.variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as td\n",
    "from torch.optim import Adam\n",
    "\n",
    "LR = 1e-3\n",
    "DATAPOINTS = len(trainset) \n",
    "BATCH_SIZE = 512 \n",
    "BATCHES = DATAPOINTS/BATCH_SIZE\n",
    "VARIABLES  = len(trainset.variables()) #9\n",
    "\n",
    "\n",
    "import Modelling\n",
    "net = Modelling.DenoisingAutoEncoder(len(trainset.variables()), theta = 7, input_dropout=0.5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "net = net.to(device) \n",
    "\n",
    "trainset = dataset_module.DataSetForImputation(train_df, normalize=True)\n",
    "# testset = dataset_module.DataSetForImputation(test_df, normalize=True)\n",
    "\n",
    "train_loader = td.DataLoader(trainset, batch_size= BATCH_SIZE, shuffle= True, **kwargs) \n",
    "\n",
    "optimizer = Adam(net.parameters(), lr = LR)\n",
    "\n",
    "LOG_INTERVAL = 10\n",
    "SAVE_INTERVAL = 50\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TO DO:\n",
    ":- Nesterov Momentum + Adam- Pytorch? Decay factor?\n",
    "'''\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train_model(start_steps = 0, end_steps = 5, net=None, model_name = \"DAE_Arch_N_7_ImputeOnlyNaNs_WithDropout\", logger_level = 20):\n",
    "    import logging\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logger_level)\n",
    "\n",
    "    NaN_flag = False\n",
    "    \n",
    "    for epoch in tqdm(range(start_steps, end_steps)):\n",
    "        count = epoch-start_steps+1\n",
    "        net.train()\n",
    "        #Epoch begins\n",
    "        epoch_loss = 0.0\n",
    "        for x, d in tqdm(train_loader):\n",
    "            # Normalize between [0,1] for better convergence \n",
    "            original_x = x\n",
    "            x[torch.isnan(x)]=0   #If an entire column is zero, division by 0, replace NaNs with zero\n",
    "            d[torch.isnan(d)]=0 \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                d = d.to(device)\n",
    "            y = net(x)\n",
    "            loss = torch.sqrt(criterion(y, d))   #RMSE Loss   \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            #Break if NaN encountered\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                logging.info(f\"Loss value: {loss.item()}\")\n",
    "                logging.info(\"NaN/inf occured at:\")\n",
    "                logging.info(f\"{x}\\n\")\n",
    "                logging.info(f\"{d}\\n\")\n",
    "                logging.info(f\"Original x was : {original_x}\")\n",
    "                NaN_flag = True\n",
    "                break\n",
    "\n",
    "            logging.debug(f\"Count: {count}, Loss :{loss}\")\n",
    "            \n",
    "        if NaN_flag: break   #Stop training if NaN encountered\n",
    "            \n",
    "        #Print to screen every few epochs    \n",
    "        if count%LOG_INTERVAL == 0:\n",
    "            print(f\"Epoch number:{epoch} Loss: {epoch_loss:.4f}\")  \n",
    "            \n",
    "        #Training artifacts\n",
    "        if model_name not in os.listdir():\n",
    "            os.makedirs(model_name+\"/artifacts/saved_model/\")\n",
    "\n",
    "        #Write to loss file every epoch\n",
    "        with open(model_name+\"/artifacts/loss_curve\",mode = 'a+') as f:\n",
    "            f.write(f\"Epoch_number: {epoch} Loss: {epoch_loss:.4f}\\n\")\n",
    "        \n",
    "        #Save model every few epochs\n",
    "        if epoch%SAVE_INTERVAL== 0:\n",
    "            torch.save(net.state_dict(),f\"./{model_name}/artifacts/saved_model/model_at_epoch{epoch}\")\n",
    "        #Epoch Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"DAE_Arch_N_7_ImputeOnlyNaNs_WithDropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(0,50, net, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Remove folder before training again'''\n",
    "# import shutil\n",
    "# shutil.rmtree(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate annealing:- Maybe need a smaller learning rate after a while? \n",
    "Nesterov momentum:- Check paper to see if all the features have been implemented exactly (like Nesterov?)\n",
    "              \n",
    "Experiments to try:\n",
    "1. Plot different values for different architectures.\n",
    "2. Try feeding in with just the imputed values instead of the whole predicted data.\n",
    "3. Try without dropout.\n",
    "\n",
    "Features needed:\n",
    "\n",
    "1. Printing out the denormalized data in prediction - DONE\n",
    "2. Store the ids of NaNs before filling them up with placeholders - Not Needed, wrote a better TEST FUNCTION\n",
    "3. Do 70/30 Split before training, testing - DONE\n",
    "4. Add provision in model for changing theta params - DONE\n",
    "5. Add provision for removing dropout - DONE\n",
    "6. Plotting Loss function - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "#torch.save(optimizer.state_dict(), filename)\n",
    "#optimizer.load_state_dict(torch.load(filename))\n",
    "\n",
    "# Modelling Loading from saved point\n",
    "\n",
    "# model =  Modelling.DenoisingAutoEncoder(len(trainset.variables()))\n",
    "# model.load_state_dict(torch.load(\"./artifacts/saved_model_epoch50\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweaking the learning rate to improve convergence speed\n",
    "# optimizer = Adam(net.parameters(), LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.eval()\n",
    "print((net(trainset[0][0]).detach()))\n",
    "print(trainset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.eval()\n",
    "print(trainset.get_denormalized_data((net(trainset[0][0].detach()))))\n",
    "print(trainset.get_denormalized_data(trainset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "def test_model(net=None, test_df= None, trainset=None, device =None, logger_level=20):\n",
    "    \"\"\"\n",
    "    Function to evaluate the model on test set\n",
    "    Should meet the following requirements:\n",
    "        :-trainset - should be an object of class DataSetForImputation\n",
    "        :-test_df - should be a Pandas dataframe with NaNs (if there are no NaNs, the same will be returned)\n",
    "        :-net - should be an object of DenoisingAutoEncoder\n",
    "    \"\"\"\n",
    "    assert isinstance(net, Modelling.DenoisingAutoEncoder)\n",
    "    assert isinstance(test_df, pd.DataFrame)\n",
    "    assert isinstance(trainset, dataset_module.DataSetForImputation)\n",
    "    \n",
    "    import logging\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logger_level)\n",
    "    \n",
    "    NaN_test_df = test_df.reset_index(drop=True)  #Dropping index so that everything is reindexed from 0\n",
    "       \n",
    "    test_df = test_df.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "    test_df_norm = (test_df- trainset.min_df)/(trainset.max_df-trainset.min_df)\n",
    "    test_df_tensor = torch.tensor(test_df_norm.values).to(device)\n",
    "        \n",
    "    net = net.eval()\n",
    "    logging.debug(f\"{test_df_tensor.shape}\")\n",
    "    pred = net(test_df_tensor)\n",
    "     \n",
    "    pred =  trainset.get_denormalized_data(pred)  #Predicted dataframe from the mode    \n",
    "    \n",
    "    # Replace the NaNs in the original test_df with newly imputed values\n",
    "    final_pred = NaN_test_df.where(~NaN_test_df.isna(), other = pred)\n",
    "    logging.debug(f\"final_pred:\\n {final_pred.head()}\")\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model(net=net, test_df=test_df, trainset=trainset, device=device,logger_level=20).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plotting Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_loss_curve(title=f\"{model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
